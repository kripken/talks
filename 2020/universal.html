<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>WebAssembly and the Elusive Universal Binary</title>

<!--
WebAssembly and the Elusive Universal Binary

Many software developers dream of a "universal binary" that would let us build
once and ship everywhere. Of course such a thing would be impossible to do
without some tradeoffs on speed or portability, but it's worth getting as close
as we can! In this talk we'll see how WebAssembly can help here both today and
in the future.
-->

    <meta name="description" content="Wasm and the Elusive Universal Binary">
    <meta name="author" content="Alon Zakai">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css" id="theme">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">

    <style type="text/css">
      h2 b {
        color: #f5f;
      }
      h3 b {
        color: #bbb;
      }
      b {
        color: #bbf;
      }
      strong {
        color: #bfb;
      }
    </style>
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h2><b>WebAssembly and the Elusive Universal Binary</b></h2>
          <p>
            <b>June 2020</b>
          </p>
          <p>
            Alon Zakai (Google)
          </p>
        </section>

        <section>
          <p>
            A "<b>Universal Binary</b>" is a single executable that
            runs on any arch and any OS, and
            runs at 100% of speed.
          </p>
          <hr>
          <p>
            The dream is you build once instead of for each target, with no downsides.
            [graphy]
          </p>
          <hr>
          <p>
            In fact, it doesn't need to actually be a <strong>binary</strong>, so long as it's
            portable and fast.
          </p>
        </section>

        <section>
          <h3><b>Example: My Use Case</b></h3>
          <hr>
          <p>
            <a href="https://github.com/WebAssembly/binaryen#tools">wasm-opt</a>
            (part of <a href="https://github.com/WebAssembly/binaryen/">binaryen</a>)
            shrinks wasm files by around <b>20%</b> on average.
          </p>
          <hr>
            Binary builds are used by toolchains like
            <a href="https://emscripten.org/">Emscripten</a> (C++)
            and <a href="https://github.com/rustwasm/wasm-pack">wasm-pack</a> (Rust).
          </p>
          <hr>
          <p>
            We have builds for <strong>Linux, Mac, and Windows</strong>, but some users can't use them (e.g. BSD).
            And build infra takes work, sometimes tests only fail there, etc.
          </p>
        </section>

        <section>
          <p>
            It would be nice if we had this:
          </p>
          <hr>
          <pre><code class="bash" data-trim>
$ make output # or any other build system
...
$ run output # on other machines too!
...
</code></pre>
          <hr>
          <p>
            How close can we get today?
          </p>
        </section>

        <section>
          <h3><b>Portability</b></h3>
          <hr>
          <p>
            First, let's distinguish two types of portability.
          </p>
          <hr>
          <p>
            <b>CPU portability</b> concerns <strong>pure computation</strong>, lets you run your code no matter what the
            CPU architecture is.
          </p>
          <hr>
          <p>
            <b>OS portability</b> concerns <strong>APIs</strong>, and lets you do operations like
            printing, file access, etc. no matter the operating system.
          </p>
        </section>

        <section>
          <p>
            <b>The Web</b> has one of the best CPU + OS portability stories. Browser-specific
            bugs definitely exist, and are annoying, but given the scale of the Web
            they are remarkably few!
          </p>
          <hr>
          <p>
            <strong>Node.js, Python, Java, .NET</strong>, and other virtual machines (VMs) provide full
            CPU portability, and some amount of OS portability. Some operations
            are OS-specific; less portable, but more power.
          </p>
          <hr>
          <p>
            Off the Web, we should use one of those <strong>VMs</strong>.
          </p>
        </section>

        <section>
          <p>
            If we have <b>C, C++, Rust, or Go</b>, what VMs can we compile to?
          </p>
          <hr>
          <p>
            All those can compile to <b>WebAssembly</b> which solves CPU
            portability! Now, where can we run it?
        </section>

        <section>
          <p>
            <b>In a console environment</b> there are two main ways to run wasm today:
          </p>
          <hr>
          <p>
            <strong>Node.js</strong>: Popular VM built on the V8 JavaScript (JS)
            engine which supports both JS and wasm.
          </p>
          <hr>
          <p>
            <strong>Wasm VMs</strong>: A new family of runtimes including:
            <a href="https://github.com/bytecodealliance/wasmtime">Wasmtime</a>,
            <a href="https://github.com/wasmerio/wasmer">Wasmer</a>,
            <a href="https://github.com/WAVM/WAVM">WAVM</a>,
            <a href="https://github.com/wasm3/wasm3">wasm3</a>, etc.
          </p>
          <hr>
          <p>
            Which of those we use determines which APIs we can use.
          </p>
        </section>

        <section>
          <h3><b>Node.js: Node.js APIs</b></h3>
          <hr>
          <p>
            Node.js APIs are a useful set of OS operations on things like
            <a href="https://nodejs.org/api/fs.html">files</a> and
            <a href="https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options">processes</a> (spawn, fork, etc.).
          </p>
          <hr>
          <pre><code class="js" data-trim>
// No special sandboxing model; like Python etc.,
// this gives the program a reasonably-portable
// set of OS operations.
const fs = require("fs");
const data = fs.readFileSync("data.dat");
// Can provide imports to wasm that use these indirectly.
</code></pre>
        </section>

        <section>
          <h3><b>WASM Runtimes: WASI APIs</b></h3>
          <hr>
          <p>
            The <a href="https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/">WebAssembly System Interface</a>,
            meant for non-Web environments.
          </p>
          <hr>
          <p>
            WASI is <b>not</b> just a bunch of familiar APIs brought to wasm! It is a
            new approach to writing an OS interface layer, a replacement for
            something like POSIX.
          </p>
          <hr>
          <p>
            In particular WASI uses
            <a href="https://en.wikipedia.org/wiki/Capability-based_security">capability-based security</a>
            and has stricter portability as well.
          </p>
        </section>

        <section>
          <h3><b>The Big Picture for APIs</b></h3>
          <hr>
          <p>
            WASI is supported on Node.js too, not just wasm VMs.
          </p>
          <hr>
          <p>
            In the long term
            WASI will likely be the best option for the things it can support.
          </p>
          <hr>
          <p>
            But WASI is still fairly new, designing a new OS API takes time,
            and the strict sandboxing will limit what can be done.
          </p>
        </section>

        <section>
          <h3><b>Compiling to WASM VMs?</b></h3>
          <hr>
          <p>
            <b>wasm-opt</b> needs C++ exceptions or setjmp
            (the optimizer uses an interpreter which has stack unwinding).
          </p>
          <hr>
          <p>
            WASI doesn't support setjmp or C++ exceptions, so that's not an
            option (yet!)
          </p>
        </section>

        <section>
          <h3><b>Compiling to wasm on node.js</b></h3>
          <hr>
          <p>
            Emscripten supports setjmp and C++ exceptions when building to JS+wasm, and it's easy
            to compile with it:
          </p>
          <pre><code class="bash" data-trim>
$ emcmake cmake .
$ make -j8 wasm-opt
</code></pre>
          <hr>
          <p>
            And so is running it:
          </p>
          <pre><code class="bash" data-trim>
$ node wasm-opt.js input.wasm -O -o output.wasm
# (note the size improvement)
$ ls -lh input.wasm output.wasm 
-rw-r--r-- 23K input.wasm
-rw-r--r-- 18K output.wasm
</code></pre>
        </section>

        <section>
          <p>
            That mostly worked out of the box, but by default Emscripten's
            output is designed to run in a browser, and is sandboxed. To get
            direct local file access in node, we use <strong>-s NODERAWFS</strong>.
          </p>
          <hr>
          <p>
            That's it! Then <b>node wasm-opt.js</b> runs the same as a normal native
            executable would.
          </p>
        </section>

        <section>
          <p>
            <b>The good:</b> It has full CPU portability, and as it only does simple file reading
            and writing Node.js APIs give us full OS portability too!
          </p>
          <hr>
          <p>
            <b>The reasonable:</b> Throughput is just <strong>28%</strong> slower than native.
          </p>
          <hr>
          <p>
            <b>The bad:</b> A startup delay of about 1 second.
          </p>
        </section>

        <section>
          <p>
            The real solution for startup is
            <a href="https://v8.dev/blog/wasm-code-caching">wasm code caching</a>,
            which works on the Web, but not yet on Node.js.
          </p>
          <hr>
          <p>
            Node 12 had an API for code caching (in Emscripten we added
            <b>-s NODE_CODE_CACHING</b>) but that
            <a href="https://github.com/nodejs/node/issues/18265#issuecomment-622971547">needs reworking</a>
            in Node 14, so it isn't possible atm.
          </p>
        </section>

        <section>
          <p>
            Maybe we don't need wasm? We can compile to <strong>JS</strong>!
          </p>
          <hr>
          </p>
            Linking with <b>-s WASM=0</b> tells Emscripten to emit JS
            instead of wasm (internally it uses wasm2js).
          </p>
          <hr>
          <p>
            Speeds up startup by almost <strong>2x</strong>!
            But as you would expect, throughput is <strong>2x</strong> slower...
          </p>
        </section>

        <section>
          <h3><b>The story so far</b></h3>
          <hr>
          <p>
            <ul>
              <li>Can't do WASI since no setjmp support <b>:(</b></li>
              <li>Can't do wasm on Node since startup is slower <b>:(</b></li>
              <li>Can't do JS on Node since throughput is slower <b>:(</b></li>
            </ul>
          </p>
          <hr>
          <p>
            Maybe we should give up?
          </p>
        </section>

        <section>
          <h3><b>wasm2c</b></h3>
          <hr>
          <p>
            Part of <a href="https://github.com/WebAssembly/wabt">wabt</a>, compiles wasm <b>&rightarrow;</b> C
          </p>
          <hr>
          <p>
            Full workflow:
            <br>
            original source <b>&rightarrow;</b> wasm <b>&rightarrow;</b> C "source" <b>&rightarrow;</b> native
          </p>
          <hr>
          <p>
            Very easy to do!
<!--  also atm           -s STANDALONE_WASM" -->
          <pre><code class="bash" data-trim>
            # tell emscripten to use wasm2c
            $ emcmake cmake . "-DCMAKE_EXE_LINKER_FLAGS=-s WASM2C"
            $ make -j8
            # build the output C normally
            $ clang wasm-opt.wasm.c -O2 -lm -o wasm-opt
            $ ./wasm-opt # runs like a normal executable!
          </code></pre>
          </p>
        </section>

        <section>
          <p>
            Wait, isn't all this a little silly? We started with C++, compiled
            to wasm, then back to C? We still need to compile that C!
          </p>
          <hr>
          <p>
            <table>
              <tr>
                <td><strong>Dev machine:</strong></td><td><center>source <b>&rightarrow;</b> wasm <b>&rightarrow;</b> C</center></td></tr>
                <td><strong>User machine:</strong></td><td><center>C <b>&rightarrow;</b> native</center></td></tr>
              </tr>
            </table>
          </p>
          <hr>
          <p>
            That C code is easy to compile since there is
            a C compiler everywhere (e.g. source could be c++20, rust nightly, etc.).
          </p>
        </section>

        <section>
          <h3><b>Our problems are solved!</b></h3>
          <hr>
          <p>
            <b>Startup is instantaneous</b>, exactly like a normal executable!
          </p>
          <hr>
          <p>
            Throughput is just <b>13%</b> slower (half the overhead of the wasm from earlier) thanks to full clang/gcc etc. optimizations!
          </p>
        </section>
        
        <section>
          <h3><b>VM-less Wasm</b></h3>
          <hr>
          <p>
            100% as <b>portable</b> as wasm in a VM
          </p>
          <hr>
          <p>
            100% as <b>sandboxed</b> as wasm in a VM
          </p>
          <hr>
          <p>
            But without a VM, which can be <strong>simpler and faster</strong>.
          </p>
        </section>

        <section>
          <h3><b>Benchmarks</b></h3>
          <hr>
					<a href="wasm2c-results.png"><img data-src="wasm2c-results.png" alt="benchmark results"></a>
					<p>
					  Just <b>14%</b> overhead on average!
					</p>
        </section>

        <section>
          <h3><b>A surprising speed benefit</b></h3>
          <hr>
          <p>
            wasm2c was <b>30%</b> faster on lua-binarytrees, <b>20%</b> on havlak! How can that be?
          </p>
          <hr>
          <p>
            Wasm is a <strong>32-bit</strong> architecture (so far). So on a 64-bit host, it's like the
            <a href="https://en.wikipedia.org/wiki/X32_ABI">x32 ABI</a>:
            save memory with half-sized pointers.
          <hr>
          <p>
            Wasm is a nice easy way to get x32-like benefits!
          </p>
        </section>

        <section>
          <h3><b>Current status of wasm2c</b></h3>
          <hr>
          <p>
            The C code builds on clang and gcc on all platforms, but we could
            use some help with MSVC and others (we use e.g. <b>__builtin_ctlz</b>).
          </p>
          <hr>
          <p>
            Currently a single big C file is emitted which
            takes a while to compile on -O2. We should split into separate files.
          </p>
        </section>

        <section>
          <p>
            wasm2c could be used with any toolchain that compiles to wasm, but
            I'm not aware of much work aside from Emscripten.
          </p>
          <hr>
          <p>
            wasm2c integration in Emscripten supports <b>practically everything</b>
            wasm can do, including setjmp, files, most C++ features (which is how
            we could run all those benchmarks! but some things are missing, like C++ exceptions)
          </p>
          <hr>
          <p>
            All of this is open source of course - <strong>help is welcome</strong>!
          </p>
        </section>

        <section>
          <h3><b>Conclusion</b></h3>
          <hr>
          <p>
            <b>wasm2c works surprisingly well!</b> Can be useful today.
          </p>
          <hr>
          <p>
            In the long term <strong>Node.js, wasm VMs, and WASI</strong> will all get better, and remove
            the limitations that we saw.
          </p>
          <hr>
          <p>
            Even so, a VM-less approach can be simpler for some things.
          </p>
          <hr>
          <p>
            For example, embedding a wasm VM is great to run arbitrary wasm
            code. But for fixed wasm code, <b>linking C or precompiled wasm</b> is easier.
          </p>
        </section>

        <section>
          <h3><b>Thank you!</b></h3>
          <hr>
          <p>
            Questions?
          </p>
        </section>

<!--http://mozakai.blogspot.com/2013/05/the-elusive-universal-web-bytecode.html-->

      </div>


    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/search/search.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>

      // Also available as an ES module, see:
      // https://revealjs.com/initialization/
      Reveal.initialize({
        controls: true,
        progress: true,
        center: true,
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
      });

    </script>

  </body>
</html>
